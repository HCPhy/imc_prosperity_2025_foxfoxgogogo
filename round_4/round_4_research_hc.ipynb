{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'base (Python 3.12.2)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. WebSocket is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import statistics as st\n",
    "\n",
    "from scipy.stats import shapiro, jarque_bera, norm\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-19T23:30:33.004109Z",
     "start_time": "2024-04-19T23:30:32.390117Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_df(round, day):\n",
    "    file_name = f\"./round-{round}-island-data-bottle/prices_round_{round}_day_{day}.csv\"\n",
    "    return pd.read_csv(file_name, sep=';')\n",
    "\n",
    "def get_product(df, product):\n",
    "    return df[df['product'] == product].copy()\n",
    "\n",
    "def get_first_two_dfs():\n",
    "    first_df = get_df(1)\n",
    "    second_df = get_df(2)\n",
    "    second_df['timestamp'] = second_df['timestamp'] + 1000000\n",
    "    return pd.concat([first_df, second_df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_obs_df(round, day):\n",
    "    file_name = f\"./round-{round}-island-data-bottle/observations_round_{round}_day_{day}.csv\"\n",
    "    return pd.read_csv(file_name, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_df = [get_df(4, day) for day in range(1, 4)]\n",
    "product_df = [get_product(prices_df[day], 'MAGNIFICENT_MACARONS')\n",
    "              for day in range(0, 3)]\n",
    "obs_df = [get_obs_df(4, day) for day in range(1, 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df[0].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_cut = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-19T23:30:34.015345Z",
     "start_time": "2024-04-19T23:30:33.919596Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_adj_mid_price_1(row):\n",
    "    weight_sum = 0;\n",
    "    total_volume = 0;\n",
    "    for i in range(1,4):\n",
    "        weight_sum += row[f'bid_volume_{i}'] * row[f'bid_price_{i}']\n",
    "        weight_sum += row[f'ask_volume_{i}'] * row[f'ask_price_{i}']\n",
    "        total_volume += row[f'bid_volume_{i}']\n",
    "        total_volume += row[f'ask_volume_{i}']\n",
    "        \n",
    "        return weight_sum / total_volume\n",
    "    \n",
    "def calc_adj_mid_price_2(row):\n",
    "    weight_sum = 0;\n",
    "    total_volume = 0;\n",
    "    for i in range(1,4):\n",
    "        weight_sum += row[f'bid_volume_{i}'] * row[f'bid_price_{i}'] if row[f'bid_volume_{i}'] > volume_cut else 0\n",
    "        weight_sum += row[f'ask_volume_{i}'] * row[f'ask_price_{i}'] if row[f'ask_volume_{i}'] > volume_cut else 0\n",
    "        total_volume += row[f'bid_volume_{i}'] if row[f'bid_volume_{i}'] > volume_cut else 0\n",
    "        total_volume += row[f'ask_volume_{i}'] if row[f'ask_volume_{i}'] > volume_cut else 0\n",
    "        \n",
    "        return weight_sum / total_volume if total_volume != 0 else calc_adj_mid_price_1(row)\n",
    "    \n",
    "def calc_adj_mid_price_hard(row):\n",
    "    weight_sum = 0;\n",
    "    total_weight = 0;\n",
    "    for i in range(1,4):\n",
    "        weight_sum += row[f'bid_price_{i}'] if row[f'bid_volume_{i}'] > volume_cut else 0\n",
    "        weight_sum += row[f'ask_price_{i}'] if row[f'ask_volume_{i}'] > volume_cut else 0\n",
    "        total_weight += 1 if row[f'bid_volume_{i}'] > volume_cut else 0\n",
    "        total_weight += 1 if row[f'ask_volume_{i}'] > volume_cut else 0\n",
    "        \n",
    "        return weight_sum / total_weight if total_weight != 0 else calc_adj_mid_price_1(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_stamp = [obs_df[day][\"timestamp\"] for day in range(0, 3)]\n",
    "sunlight = [obs_df[day][\"sunlightIndex\"] for day in range(0, 3)]\n",
    "sugar_price = [obs_df[day][\"sugarPrice\"] for day in range(0, 3)]\n",
    "trans_fee = [obs_df[day][\"transportFees\"] for day in range(0, 3)]\n",
    "exp_tariffs = [obs_df[day][\"exportTariff\"] for day in range(0, 3)]\n",
    "imp_tariffs = [obs_df[day][\"importTariff\"] for day in range(0, 3)]\n",
    "mid_price_ext = [(obs_df[day][\"bidPrice\"] + obs_df[day][\"askPrice\"]) / 2 for day in range(0, 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "X_series = [np.column_stack([sunlight[day], sugar_price[day], trans_fee[day],\n",
    "                            exp_tariffs[day], imp_tariffs[day]]) for day in range(0, 3)]\n",
    "\n",
    "Features = copy.deepcopy(X_series)\n",
    "\n",
    "for day in range(0, 3):\n",
    "    for i in range(X_series[0].shape[1]):\n",
    "        for j in range(X_series[0].shape[1]):\n",
    "            Features[day] = np.c_[Features[day],\n",
    "                                  Features[day][:, i] * Features[day][:, j]]\n",
    "\n",
    "# Third order terms seems useless\n",
    "# for day in range(0, 3):\n",
    "#     for i in range(X_series[0].shape[1]):\n",
    "#         for j in range(X_series[0].shape[1]):\n",
    "#             for k in range(X_series[0].shape[1]):\n",
    "#                 Features[day] = np.c_[Features[day], Features[day]\n",
    "#                                       [:, i] * Features[day][:, j] * Features[day][:, k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for day in range(0, 3):\n",
    "    product_df[day]['adj_mid_price'] = product_df[day].apply(\n",
    "        calc_adj_mid_price_1, axis=1)\n",
    "mid_price_local = [product_df[day]['adj_mid_price'].to_numpy()\n",
    "                   for day in range(0, 3)]\n",
    "\n",
    "mid_price_diff = [mid_price_local[day] - mid_price_ext[day]\n",
    "                  for day in range(0, 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for day in range(0,3):\n",
    "    plt.plot(time_stamp[day], mid_price_diff[day])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor, Lasso\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "reg = make_pipeline(StandardScaler(), Lasso(alpha = 0.18, max_iter=10000))\n",
    "reg.fit(np.concatenate((Features[0], Features[1]), axis=0), \n",
    "        np.concatenate((mid_price_local[0], mid_price_local[1]), axis=0))\n",
    "# print(f\"alpha = {alp}, MES = {mean_squared_error(mid_price_local[2],reg.predict(Features[2]))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_squared_error(mid_price_local[2],reg.predict(Features[2])))\n",
    "plt.plot(reg.steps[-1][1].coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for day in range(0, 3):\n",
    "    plt.plot(time_stamp[day], reg.predict(Features[day]))\n",
    "    plt.plot(time_stamp[day], mid_price_local[day])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_gbm(time_series, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Check if a time series is compatible with a geometric Brownian motion.\n",
    "\n",
    "    Parameters:\n",
    "        time_series (np.array): 1D array of prices.\n",
    "        alpha (float): Significance level for hypothesis tests.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary of test results for normality and independence.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    # 1. Log transform the series so that: X_t = log(S_t)\n",
    "    log_series = np.log(time_series)\n",
    "\n",
    "    # 2. Compute the log returns (increments): ΔX_t = X_t+Δt - X_t\n",
    "    log_returns = np.diff(log_series)\n",
    "\n",
    "    # 3. Test for normality\n",
    "    #    a. Shapiro-Wilk test\n",
    "    shapiro_stat, shapiro_p = shapiro(log_returns)\n",
    "    results['Shapiro-Wilk'] = {'statistic': shapiro_stat, 'p-value': shapiro_p,\n",
    "                               'normality': shapiro_p > alpha}\n",
    "\n",
    "    #    b. Jarque-Bera test\n",
    "    jb_stat, jb_p = jarque_bera(log_returns)\n",
    "    results['Jarque-Bera'] = {'statistic': jb_stat, 'p-value': jb_p,\n",
    "                              'normality': jb_p > alpha}\n",
    "\n",
    "    # 4. Test for independence (no autocorrelation) using the Ljung-Box test\n",
    "    #    Here we test at a fixed lag (e.g., 10). Adjust lags as needed.\n",
    "    lb_test = acorr_ljungbox(log_returns, lags=[50], return_df=True)\n",
    "    lb_p_value = lb_test['lb_pvalue'].iloc[-1]\n",
    "    results['Ljung-Box'] = {'lag': 50, 'p-value': lb_p_value,\n",
    "                            'independence': lb_p_value > alpha}\n",
    "\n",
    "    # 5. Diagnostic plots\n",
    "    #    a. QQ-plot to assess normality\n",
    "    sm.qqplot(log_returns, line='45', fit=True)\n",
    "    plt.title('QQ-Plot of Log Returns')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    #    b. Histogram with fitted normal distribution\n",
    "    plt.hist(log_returns, bins=30, density=True,\n",
    "             alpha=0.6, color='skyblue', edgecolor='k')\n",
    "    mu, sigma = np.mean(log_returns), np.std(log_returns)\n",
    "    x_vals = np.linspace(log_returns.min(), log_returns.max(), 100)\n",
    "    plt.plot(x_vals, norm.pdf(x_vals, mu, sigma), 'r', lw=2)\n",
    "    plt.title('Histogram of Log Returns')\n",
    "    plt.xlabel('Log Return')\n",
    "    plt.ylabel('Density')\n",
    "    plt.show()\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day1_product_df['adj_mid_price'] = day1_product_df.apply(calc_adj_mid_price_2, axis = 1)\n",
    "\n",
    "# day1_product_df.plot(x='timestamp',y='mid_price')\n",
    "# day1_product_df.plot(x='timestamp',y='adj_mid_price')\n",
    "# plt.show()\n",
    "\n",
    "mid_pirce_series = day1_product_df['adj_mid_price'].to_numpy()\n",
    "# plt.plot(np.diff(np.log(mid_pirce_series)))\n",
    "\n",
    "test_results = check_gbm(mid_pirce_series[5000:5500])\n",
    "for test, res in test_results.items():\n",
    "    print(f\"{test}: {res}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day1_product_df['adj_mid_price'] = day1_product_df.apply(calc_adj_mid_price_2, axis = 1)\n",
    "\n",
    "# day1_product_df.plot(x='timestamp',y='mid_price')\n",
    "# day1_product_df.plot(x='timestamp',y='adj_mid_price')\n",
    "# plt.show()\n",
    "\n",
    "mid_pirce_series = day1_product_df['adj_mid_price'].to_numpy()\n",
    "return_series = np.diff(mid_pirce_series)\n",
    "Log_price_series = log_series = np.log(mid_pirce_series)\n",
    "log_return_series = np.diff(Log_price_series)\n",
    "# plt.plot(np.diff(np.log(mid_pirce_series)))\n",
    "\n",
    "test_results = check_gbm(mid_pirce_series[:])\n",
    "for test, res in test_results.items():\n",
    "    print(f\"{test}: {res}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_markov(time_series, scaling_factor=200):\n",
    "    markov_trans_mat = np.zeros((int(max(time_series) * scaling_factor) - int(min(time_series) * scaling_factor) + 1,\n",
    "                                 int(max(time_series) * scaling_factor) - int(min(time_series) * scaling_factor) + 1))\n",
    "    markov_freq_mat = np.zeros((int(max(time_series) * scaling_factor) - int(min(time_series) * scaling_factor) + 1,\n",
    "                                int(max(time_series) * scaling_factor) - int(min(time_series) * scaling_factor) + 1))\n",
    "\n",
    "    for i in range(len(time_series) - 1):\n",
    "        state_now = int(time_series[i] * scaling_factor) - \\\n",
    "            int(min(time_series) * scaling_factor)\n",
    "        state_next = int(time_series[i + 1] * scaling_factor) - \\\n",
    "            int(min(time_series) * scaling_factor)\n",
    "        markov_freq_mat[state_now][state_next] += 1\n",
    "\n",
    "    markov_trans_mat = markov_freq_mat / (1.0 + i)\n",
    "\n",
    "    return markov_trans_mat, markov_freq_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markov_trans_mat, markov_freq_mat = calc_markov(return_series[3000:], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = np.meshgrid(np.arange(markov_trans_mat.shape[1]), np.arange(\n",
    "    markov_trans_mat.shape[0]))\n",
    "\n",
    "# Plot the surface\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.plot_surface(x, y, markov_trans_mat, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(markov_trans_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocorrelation(series: np.array, lags):\n",
    "    # 计算lags阶以内的自相关系数，返回lags个值，分别计算序列均值，标准差\n",
    "    n = len(series)\n",
    "    result = [np.correlate(series[i:]-series[i:].mean(), series[:n-i]-series[:n-i].mean())[0]\n",
    "                / (series[i:].std()*series[:n-i].std()*(n-i))\n",
    "                for i in range(1, lags+1)]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(autocorrelation(log_return_series, len(log_return_series) - 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "python",
   "version": "3.12.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
